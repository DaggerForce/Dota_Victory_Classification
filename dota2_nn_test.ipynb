{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional Model\n",
    "\n",
    "## ANN to classify the outcome of a dota match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Riki</th>\n",
       "      <th>Razor</th>\n",
       "      <th>Morphling</th>\n",
       "      <th>Brewmaster</th>\n",
       "      <th>Slardar</th>\n",
       "      <th>Wisp</th>\n",
       "      <th>Omniknight</th>\n",
       "      <th>Slark</th>\n",
       "      <th>Ogre Magi</th>\n",
       "      <th>Chaos Knight</th>\n",
       "      <th>...</th>\n",
       "      <th>Carry</th>\n",
       "      <th>Support</th>\n",
       "      <th>Offlane</th>\n",
       "      <th>Mid</th>\n",
       "      <th>Roamer</th>\n",
       "      <th>Nukers</th>\n",
       "      <th>Disablers</th>\n",
       "      <th>High_Win</th>\n",
       "      <th>Low_Win</th>\n",
       "      <th>Won</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5.253443</td>\n",
       "      <td>-0.155243</td>\n",
       "      <td>-0.186940</td>\n",
       "      <td>-0.181034</td>\n",
       "      <td>-0.187513</td>\n",
       "      <td>-0.21094</td>\n",
       "      <td>-0.183669</td>\n",
       "      <td>-0.245093</td>\n",
       "      <td>-0.197112</td>\n",
       "      <td>-0.211026</td>\n",
       "      <td>...</td>\n",
       "      <td>0.414513</td>\n",
       "      <td>-0.570063</td>\n",
       "      <td>1.007526</td>\n",
       "      <td>1.261730</td>\n",
       "      <td>0.157217</td>\n",
       "      <td>0.533190</td>\n",
       "      <td>0.532469</td>\n",
       "      <td>0.474901</td>\n",
       "      <td>-0.814275</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>5.253443</td>\n",
       "      <td>-0.155243</td>\n",
       "      <td>-0.186940</td>\n",
       "      <td>-0.181034</td>\n",
       "      <td>-0.187513</td>\n",
       "      <td>-0.21094</td>\n",
       "      <td>-0.183669</td>\n",
       "      <td>-0.245093</td>\n",
       "      <td>-0.197112</td>\n",
       "      <td>-0.211026</td>\n",
       "      <td>...</td>\n",
       "      <td>0.414513</td>\n",
       "      <td>-0.570063</td>\n",
       "      <td>1.007526</td>\n",
       "      <td>0.266544</td>\n",
       "      <td>0.157217</td>\n",
       "      <td>-0.490404</td>\n",
       "      <td>-0.498516</td>\n",
       "      <td>0.474901</td>\n",
       "      <td>0.667752</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-0.190351</td>\n",
       "      <td>6.441500</td>\n",
       "      <td>-0.186940</td>\n",
       "      <td>-0.181034</td>\n",
       "      <td>-0.187513</td>\n",
       "      <td>-0.21094</td>\n",
       "      <td>-0.183669</td>\n",
       "      <td>-0.245093</td>\n",
       "      <td>-0.197112</td>\n",
       "      <td>-0.211026</td>\n",
       "      <td>...</td>\n",
       "      <td>1.498774</td>\n",
       "      <td>0.549757</td>\n",
       "      <td>-1.304373</td>\n",
       "      <td>0.266544</td>\n",
       "      <td>-1.058379</td>\n",
       "      <td>0.533190</td>\n",
       "      <td>-0.498516</td>\n",
       "      <td>1.805530</td>\n",
       "      <td>-0.814275</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>-0.190351</td>\n",
       "      <td>6.441500</td>\n",
       "      <td>5.349299</td>\n",
       "      <td>-0.181034</td>\n",
       "      <td>-0.187513</td>\n",
       "      <td>-0.21094</td>\n",
       "      <td>5.444586</td>\n",
       "      <td>-0.245093</td>\n",
       "      <td>-0.197112</td>\n",
       "      <td>-0.211026</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.669748</td>\n",
       "      <td>0.549757</td>\n",
       "      <td>-1.304373</td>\n",
       "      <td>-0.728642</td>\n",
       "      <td>0.157217</td>\n",
       "      <td>1.556785</td>\n",
       "      <td>-0.498516</td>\n",
       "      <td>-0.855727</td>\n",
       "      <td>0.667752</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5.253443</td>\n",
       "      <td>-0.155243</td>\n",
       "      <td>-0.186940</td>\n",
       "      <td>5.523822</td>\n",
       "      <td>-0.187513</td>\n",
       "      <td>-0.21094</td>\n",
       "      <td>-0.183669</td>\n",
       "      <td>-0.245093</td>\n",
       "      <td>5.073260</td>\n",
       "      <td>-0.211026</td>\n",
       "      <td>...</td>\n",
       "      <td>1.498774</td>\n",
       "      <td>1.669576</td>\n",
       "      <td>-0.148424</td>\n",
       "      <td>-0.728642</td>\n",
       "      <td>0.157217</td>\n",
       "      <td>0.533190</td>\n",
       "      <td>1.563455</td>\n",
       "      <td>-0.855727</td>\n",
       "      <td>-0.814275</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 111 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Riki     Razor  Morphling  Brewmaster   Slardar     Wisp  Omniknight  \\\n",
       "0  5.253443 -0.155243  -0.186940   -0.181034 -0.187513 -0.21094   -0.183669   \n",
       "1  5.253443 -0.155243  -0.186940   -0.181034 -0.187513 -0.21094   -0.183669   \n",
       "2 -0.190351  6.441500  -0.186940   -0.181034 -0.187513 -0.21094   -0.183669   \n",
       "3 -0.190351  6.441500   5.349299   -0.181034 -0.187513 -0.21094    5.444586   \n",
       "4  5.253443 -0.155243  -0.186940    5.523822 -0.187513 -0.21094   -0.183669   \n",
       "\n",
       "      Slark  Ogre Magi  Chaos Knight  ...     Carry   Support   Offlane  \\\n",
       "0 -0.245093  -0.197112     -0.211026  ...  0.414513 -0.570063  1.007526   \n",
       "1 -0.245093  -0.197112     -0.211026  ...  0.414513 -0.570063  1.007526   \n",
       "2 -0.245093  -0.197112     -0.211026  ...  1.498774  0.549757 -1.304373   \n",
       "3 -0.245093  -0.197112     -0.211026  ... -0.669748  0.549757 -1.304373   \n",
       "4 -0.245093   5.073260     -0.211026  ...  1.498774  1.669576 -0.148424   \n",
       "\n",
       "        Mid    Roamer    Nukers  Disablers  High_Win   Low_Win  Won  \n",
       "0  1.261730  0.157217  0.533190   0.532469  0.474901 -0.814275    1  \n",
       "1  0.266544  0.157217 -0.490404  -0.498516  0.474901  0.667752    1  \n",
       "2  0.266544 -1.058379  0.533190  -0.498516  1.805530 -0.814275    1  \n",
       "3 -0.728642  0.157217  1.556785  -0.498516 -0.855727  0.667752    1  \n",
       "4 -0.728642  0.157217  0.533190   1.563455 -0.855727 -0.814275    1  \n",
       "\n",
       "[5 rows x 111 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# open the pre-processed csv file and split the target variable from the classifiers\n",
    "df = pd.read_csv('dota2_scaled.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 110)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split the target from the features\n",
    "target = df['Won']\n",
    "df = df.drop(['Won'], axis=1)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_model, x_test, y_model, y_test = train_test_split(df, target, test_size=0.20, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize Sequential model\n",
    "model = Sequential()\n",
    "#intitalize input layer \n",
    "model.add(Dense(8, input_dim=110, activation='tanh'))\n",
    "#hidden layers with relu activation\n",
    "model.add(Dense(3000, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "#output layer \n",
    "model.add(Dense(2, activation='sigmoid'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',  optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Programs\\Anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "Epoch 1/40\n",
      "24000/24000 [==============================] - 12s 490us/step - loss: 0.6874 - acc: 0.5452\n",
      "Epoch 2/40\n",
      "24000/24000 [==============================] - 9s 354us/step - loss: 0.6802 - acc: 0.5650\n",
      "Epoch 3/40\n",
      "24000/24000 [==============================] - 9s 375us/step - loss: 0.6765 - acc: 0.5747\n",
      "Epoch 4/40\n",
      "24000/24000 [==============================] - 10s 415us/step - loss: 0.6743 - acc: 0.5795\n",
      "Epoch 5/40\n",
      "24000/24000 [==============================] - 9s 385us/step - loss: 0.6734 - acc: 0.5797\n",
      "Epoch 6/40\n",
      "24000/24000 [==============================] - 9s 355us/step - loss: 0.6714 - acc: 0.5854\n",
      "Epoch 7/40\n",
      "24000/24000 [==============================] - 9s 356us/step - loss: 0.6706 - acc: 0.5862\n",
      "Epoch 8/40\n",
      "24000/24000 [==============================] - 9s 361us/step - loss: 0.6689 - acc: 0.5887\n",
      "Epoch 9/40\n",
      "24000/24000 [==============================] - 9s 378us/step - loss: 0.6682 - acc: 0.5914\n",
      "Epoch 10/40\n",
      "24000/24000 [==============================] - 9s 370us/step - loss: 0.6670 - acc: 0.5956\n",
      "Epoch 11/40\n",
      "24000/24000 [==============================] - 9s 364us/step - loss: 0.6656 - acc: 0.5951\n",
      "Epoch 12/40\n",
      "24000/24000 [==============================] - 10s 417us/step - loss: 0.6635 - acc: 0.5985\n",
      "Epoch 13/40\n",
      "24000/24000 [==============================] - 9s 377us/step - loss: 0.6627 - acc: 0.5974\n",
      "Epoch 14/40\n",
      "24000/24000 [==============================] - 9s 386us/step - loss: 0.6608 - acc: 0.6005\n",
      "Epoch 15/40\n",
      "24000/24000 [==============================] - 9s 387us/step - loss: 0.6596 - acc: 0.6033\n",
      "Epoch 16/40\n",
      "24000/24000 [==============================] - 9s 393us/step - loss: 0.6579 - acc: 0.6075\n",
      "Epoch 17/40\n",
      "24000/24000 [==============================] - 10s 407us/step - loss: 0.6561 - acc: 0.6120\n",
      "Epoch 18/40\n",
      "24000/24000 [==============================] - 9s 395us/step - loss: 0.6558 - acc: 0.6100\n",
      "Epoch 19/40\n",
      "24000/24000 [==============================] - 9s 388us/step - loss: 0.6538 - acc: 0.6118\n",
      "Epoch 20/40\n",
      "24000/24000 [==============================] - 9s 388us/step - loss: 0.6524 - acc: 0.6164\n",
      "Epoch 21/40\n",
      "24000/24000 [==============================] - 10s 407us/step - loss: 0.6504 - acc: 0.6194\n",
      "Epoch 22/40\n",
      "24000/24000 [==============================] - 9s 366us/step - loss: 0.6487 - acc: 0.6227\n",
      "Epoch 23/40\n",
      "24000/24000 [==============================] - 10s 407us/step - loss: 0.6456 - acc: 0.6275\n",
      "Epoch 24/40\n",
      "24000/24000 [==============================] - 9s 375us/step - loss: 0.6448 - acc: 0.6291\n",
      "Epoch 25/40\n",
      "24000/24000 [==============================] - 9s 366us/step - loss: 0.6439 - acc: 0.6324\n",
      "Epoch 26/40\n",
      "24000/24000 [==============================] - 9s 394us/step - loss: 0.6413 - acc: 0.6355\n",
      "Epoch 27/40\n",
      "24000/24000 [==============================] - 10s 407us/step - loss: 0.6400 - acc: 0.6358\n",
      "Epoch 28/40\n",
      "24000/24000 [==============================] - 9s 367us/step - loss: 0.6365 - acc: 0.6408\n",
      "Epoch 29/40\n",
      "24000/24000 [==============================] - 9s 384us/step - loss: 0.6348 - acc: 0.6432\n",
      "Epoch 30/40\n",
      "24000/24000 [==============================] - 9s 383us/step - loss: 0.6332 - acc: 0.6453 \n",
      "Epoch 31/40\n",
      "24000/24000 [==============================] - 9s 390us/step - loss: 0.6299 - acc: 0.6480\n",
      "Epoch 32/40\n",
      "24000/24000 [==============================] - 10s 400us/step - loss: 0.6301 - acc: 0.6498\n",
      "Epoch 33/40\n",
      "24000/24000 [==============================] - 9s 377us/step - loss: 0.6267 - acc: 0.6532\n",
      "Epoch 34/40\n",
      "24000/24000 [==============================] - 10s 415us/step - loss: 0.6238 - acc: 0.6549\n",
      "Epoch 35/40\n",
      "24000/24000 [==============================] - 10s 417us/step - loss: 0.6218 - acc: 0.6568\n",
      "Epoch 36/40\n",
      "24000/24000 [==============================] - 9s 393us/step - loss: 0.6184 - acc: 0.6612 1s - loss: 0.6163\n",
      "Epoch 37/40\n",
      "24000/24000 [==============================] - 10s 409us/step - loss: 0.6166 - acc: 0.6647\n",
      "Epoch 38/40\n",
      "24000/24000 [==============================] - 9s 385us/step - loss: 0.6128 - acc: 0.6665\n",
      "Epoch 39/40\n",
      "24000/24000 [==============================] - 7s 293us/step - loss: 0.6102 - acc: 0.6715 \n",
      "Epoch 40/40\n",
      "24000/24000 [==============================] - 4s 183us/step - loss: 0.6082 - acc: 0.6697\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x26d32d92088>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_model, y_model, epochs=40, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000/6000 [==============================] - 1s 120us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7620130071640014, 0.5365]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 24000 samples, validate on 6000 samples\n",
      "Epoch 1/20\n",
      "24000/24000 [==============================] - 5s 224us/sample - loss: 0.6849 - sparse_categorical_accuracy: 0.5529 - val_loss: 0.6812 - val_sparse_categorical_accuracy: 0.5705\n",
      "Epoch 2/20\n",
      "24000/24000 [==============================] - 4s 147us/sample - loss: 0.6719 - sparse_categorical_accuracy: 0.5820 - val_loss: 0.6810 - val_sparse_categorical_accuracy: 0.5592\n",
      "Epoch 3/20\n",
      "24000/24000 [==============================] - 2s 101us/sample - loss: 0.6585 - sparse_categorical_accuracy: 0.5990 - val_loss: 0.6864 - val_sparse_categorical_accuracy: 0.5582\n",
      "Epoch 4/20\n",
      "24000/24000 [==============================] - 2s 97us/sample - loss: 0.6373 - sparse_categorical_accuracy: 0.6310 - val_loss: 0.7018 - val_sparse_categorical_accuracy: 0.5533\n",
      "Epoch 5/20\n",
      "24000/24000 [==============================] - 2s 100us/sample - loss: 0.6030 - sparse_categorical_accuracy: 0.6670 - val_loss: 0.7228 - val_sparse_categorical_accuracy: 0.5428\n",
      "Epoch 6/20\n",
      "24000/24000 [==============================] - 2s 100us/sample - loss: 0.5664 - sparse_categorical_accuracy: 0.7008 - val_loss: 0.7954 - val_sparse_categorical_accuracy: 0.5290\n",
      "Epoch 7/20\n",
      "24000/24000 [==============================] - 2s 98us/sample - loss: 0.5207 - sparse_categorical_accuracy: 0.7362 - val_loss: 0.8313 - val_sparse_categorical_accuracy: 0.5323\n",
      "Epoch 8/20\n",
      "24000/24000 [==============================] - 2s 83us/sample - loss: 0.4767 - sparse_categorical_accuracy: 0.7664 - val_loss: 0.9217 - val_sparse_categorical_accuracy: 0.5285\n",
      "Epoch 9/20\n",
      "24000/24000 [==============================] - 2s 76us/sample - loss: 0.4354 - sparse_categorical_accuracy: 0.7894 - val_loss: 0.9729 - val_sparse_categorical_accuracy: 0.5183\n",
      "Epoch 10/20\n",
      "24000/24000 [==============================] - 2s 74us/sample - loss: 0.3903 - sparse_categorical_accuracy: 0.8184 - val_loss: 1.1242 - val_sparse_categorical_accuracy: 0.5275\n",
      "Epoch 11/20\n",
      "24000/24000 [==============================] - 2s 77us/sample - loss: 0.3507 - sparse_categorical_accuracy: 0.8421 - val_loss: 1.1832 - val_sparse_categorical_accuracy: 0.5212\n",
      "Epoch 12/20\n",
      "24000/24000 [==============================] - 3s 117us/sample - loss: 0.3140 - sparse_categorical_accuracy: 0.8627 - val_loss: 1.4157 - val_sparse_categorical_accuracy: 0.5150\n",
      "Epoch 13/20\n",
      "24000/24000 [==============================] - 3s 121us/sample - loss: 0.2789 - sparse_categorical_accuracy: 0.8790 - val_loss: 1.4961 - val_sparse_categorical_accuracy: 0.5140\n",
      "Epoch 14/20\n",
      "24000/24000 [==============================] - 2s 89us/sample - loss: 0.2487 - sparse_categorical_accuracy: 0.8954 - val_loss: 1.6132 - val_sparse_categorical_accuracy: 0.5097\n",
      "Epoch 15/20\n",
      "24000/24000 [==============================] - 2s 76us/sample - loss: 0.2239 - sparse_categorical_accuracy: 0.9063 - val_loss: 1.7355 - val_sparse_categorical_accuracy: 0.5108\n",
      "Epoch 16/20\n",
      "24000/24000 [==============================] - 2s 78us/sample - loss: 0.2017 - sparse_categorical_accuracy: 0.9169 - val_loss: 1.9662 - val_sparse_categorical_accuracy: 0.5205\n",
      "Epoch 17/20\n",
      "24000/24000 [==============================] - 2s 77us/sample - loss: 0.1830 - sparse_categorical_accuracy: 0.9251 - val_loss: 1.9202 - val_sparse_categorical_accuracy: 0.5083\n",
      "Epoch 18/20\n",
      "24000/24000 [==============================] - 2s 87us/sample - loss: 0.1677 - sparse_categorical_accuracy: 0.9335 - val_loss: 2.1064 - val_sparse_categorical_accuracy: 0.5117\n",
      "Epoch 19/20\n",
      "24000/24000 [==============================] - 2s 93us/sample - loss: 0.1544 - sparse_categorical_accuracy: 0.9395 - val_loss: 2.2603 - val_sparse_categorical_accuracy: 0.5195\n",
      "Epoch 20/20\n",
      "24000/24000 [==============================] - 2s 87us/sample - loss: 0.1332 - sparse_categorical_accuracy: 0.9492 - val_loss: 2.2471 - val_sparse_categorical_accuracy: 0.5125\n"
     ]
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(110,), name='digits')\n",
    "x = layers.Dense(256, activation='relu', name='dense_1')(inputs)\n",
    "x = layers.Dense(128, activation='relu', name='dense_2')(x)\n",
    "x = layers.Dense(32, activation='relu', name='dense_3')(x)\n",
    "x = layers.Dense(32, activation='relu', name='dense_4')(x)\n",
    "x = layers.Dense(8, activation='relu', name='dense_5')(x)\n",
    "outputs = layers.Dense(2, activation='sigmoid', name='predictions')(x)\n",
    "\n",
    "model2 = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "\n",
    "\n",
    "model2.compile(optimizer=keras.optimizers.RMSprop(),  # Optimizer\n",
    "              # Loss function to minimize\n",
    "              loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "              # List of metrics to monitor\n",
    "              metrics=[keras.metrics.SparseCategoricalAccuracy()])\n",
    "\n",
    "history = model2.fit(x_model, y_model,\n",
    "                    batch_size=100,\n",
    "                    epochs=20,\n",
    "                    # We pass some validation for\n",
    "                    # monitoring validation loss and metrics\n",
    "                    # at the end of each epoch\n",
    "                    validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
